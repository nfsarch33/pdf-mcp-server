# Quick Reference Card: Daily Programming Standards

**Print or bookmark this page for instant access**

---

## Python Standards (uv + conda)

```bash
# Setup
uv init myproject && uv sync

# Quality Gates
✓ Type hints on public APIs
✓ Docstrings (module, class, function)
✓ ruff check && mypy passing
✓ pytest >= 80% coverage
✓ uv.lock committed

# Common Pattern
def process_items(items: list[str], timeout: int = 30) -> dict[str, int]:
    """Process items and return counts."""
    try:
        validate(items)
    except ValueError as e:
        logger.error(f"Validation failed: {e}")
        raise
    return {item: len(item) for item in items}

# Key Rules
- Use uv, not pip (10x faster)
- Use logger, not print()
- Custom exceptions, not bare except
```

---

## Go Standards (1.25)

```go
// Setup
go mod init example.com/project

// Quality Gates
✓ go fmt applied
✓ go vet passing
✓ golangci-lint clean
✓ Errors wrapped with context
✓ Context passed to goroutines

// Common Pattern
func Fetch(ctx context.Context, id string) (Data, error) {
    select {
    case <-ctx.Done():
        return nil, fmt.Errorf("fetch cancelled: %w", ctx.Err())
    default:
    }
    // Implementation...
    return data, nil
}

// Key Rules
- ALWAYS check err != nil
- Wrap errors: fmt.Errorf("operation: %w", err)
- Context first parameter
- Interface at consumer, not provider
```

---

## MCP Server Standards (2025)

```yaml
# Quality Gates
✓ JSON Schema validation on all args
✓ Version number incremented (semver)
✓ Canary deployment < 10% traffic
✓ SLO metrics monitored (p95 < 1200ms, error < 2%)
✓ RBAC scopes enforced

# Prompt Structure
id: summarizer
version: 2.0.0
status: stable
arguments:
  type: object
  required: [text]
  properties:
    text: { type: string, minLength: 50, maxLength: 20000 }
  additionalProperties: false

# Key Rules
- Stateless prompts (no side-effects)
- Actions → tools
- Validate all inputs
- Monitor with OpenTelemetry
```

---

## API & Microservices

```yaml
# Quality Gates
✓ OpenAPI spec matches code
✓ X-Request-ID on all endpoints
✓ Structured error codes + messages
✓ Retry with exponential backoff
✓ Circuit breaker for dependencies

# Endpoint Pattern
GET /v1/users/{id}
Headers: X-Request-ID: uuid
Response:
  {
    "data": { ... },
    "meta": { "request_id": "uuid" },
    "errors": null
  }

# Error Pattern
{
  "errors": [{
    "code": "INVALID_REQUEST",
    "message": "Email required",
    "field": "email"
  }],
  "meta": { "request_id": "uuid" }
}

# Key Rules
- Design-first (OpenAPI → code)
- All endpoints traceable
- Pagination for large results
- Consistent versioning
```

---

## Academic Research Code

```bash
# Quality Gates
✓ Random seeds fixed: np.random.seed(42)
✓ Hyperparameters logged in results/
✓ uv.lock committed (exact versions)
✓ Dataset versioned separately (Zenodo DOI)
✓ Figures generated by code, not manual

# Project Structure
project/
├── src/                      # Research code
├── pyproject.toml + uv.lock # Exact environment
├── results/config.json      # Hyperparams
├── results/metrics.json     # Results
├── data/                    # (or: Zenodo reference)
└── reproduce.py             # Single-command regenerate

# Key Rules
- Log hyperparams BEFORE running
- Fix random seeds
- Commit lock files
- Document dataset source
- Make figures reproducible
```

---

## AI Context Engineering

```
3-Layer Context Strategy:

Layer 1: INSTRUCTIONAL
├─ Goals: "Summarize without losing context"
├─ Constraints: "Max 200 words, cite sources"
└─ Format: "Output JSON"

Layer 2: KNOWLEDGE
├─ Domain facts (API docs, schemas)
├─ Code examples
└─ Patterns

Layer 3: TOOL
├─ Available functions
├─ Parameters
└─ Expected outputs

Memory Quality Gates:
1. Needed EVERY conversation? → No → Use Pepper
2. Fits 1 paragraph? → No → Use Pepper
3. Rule not task? → No → Don't memorize
```

---

## Quality Gate Checklist (Universal)

```
BEFORE COMMITTING:
☐ No TODO comments left
☐ No hardcoded secrets
☐ Error handling for all paths
☐ Tests passing
☐ Linting clean
☐ Dependencies reproducible
☐ Code review ready

LANGUAGE SPECIFIC:
☐ Python: Type hints + docstrings + pytest
☐ Go: Error wrapping + context + table tests
☐ MCP: Schema validation + versioning
☐ API: OpenAPI spec + request IDs
☐ Academic: Seed fixed + hyperparams logged
```

---

## Common Commands

### Python
```bash
uv init project && cd project     # Create project
uv sync                            # Install deps
uv run pytest tests/               # Run tests
uv run ruff check .                # Lint
uv run mypy .                      # Type check
uv lock                            # Update lockfile
```

### Go
```bash
go mod init example.com/project   # Create project
go test ./...                      # Run tests
go fmt ./...                       # Format
go vet ./...                       # Lint
golangci-lint run                  # Full lint
go run cmd/server/main.go          # Run
```

### Memory (Cursor)
```
memory_bank_read("global-memories", "coding-standards-v9-1.md")
memory_bank_update("global-memories", "file.md", "content")
```

---

## Language Choice Guide

| Problem | Language | Reason |
|---------|----------|--------|
| API/Microservice | Go | Fast, concurrent, stdlib |
| Data Science/ML | Python | Rich ecosystem, uv efficient |
| Research Paper | Python | Reproducibility, Jupyter |
| CLI Tool | Go | Single binary, fast startup |
| Web App | Python | FastAPI/Django flexibility |
| System Tool | Go | Performance, concurrency |
| LLM Integration | Python | transformers, langchain |
| Production Server | Go | Reliability, monitoring |

---

## Quick Diagnostics

**Python code slow?**
- [ ] Using venv? Switch to uv (10x faster)
- [ ] Missing type hints? Run mypy
- [ ] Tests passing? Check coverage >= 80%

**Go code failing?**
- [ ] Error wrapped? Use fmt.Errorf("op: %w", err)
- [ ] Context passed? Check first parameter
- [ ] Tests exist? Write table-driven tests

**MCP server issues?**
- [ ] Arguments validated? Add JSON Schema
- [ ] Errors monitored? Enable OpenTelemetry
- [ ] Version incremented? Use semver

**API failing?**
- [ ] OpenAPI spec matches? Review spec vs code
- [ ] Request ID in response? Add X-Request-ID
- [ ] Errors structured? Use error codes

**Research not reproducible?**
- [ ] uv.lock committed? Check git
- [ ] Seed fixed? Add np.random.seed(42)
- [ ] Hyperparams logged? Save to JSON
- [ ] Dataset versioned? Link to Zenodo

---

## When in Doubt

### Ask Cursor Memory
```
In any Cursor conversation, type:
"show me [language] standards"
"[language] quality gates checklist"
"best practices for [topic]"

Cursor will:
1. Load coding-standards-v9-1.md
2. Find relevant section
3. Show examples + checklist
```

### Quick Search
```bash
# Find relevant standard
grep -A 20 "Python" ~/memo/global-memories/coding-standards-v9-1.md
grep -A 20 "Go" ~/memo/global-memories/coding-standards-v9-1.md
grep -A 20 "MCP" ~/memo/global-memories/coding-standards-v9-1.md
```

---

## Version Info

| Component | Version | Date |
|-----------|---------|------|
| Python | 3.11+ | 2025 |
| Go | 1.25 | 2025 |
| uv | Latest | 2025 |
| MCP Spec | 2025-03-26 | 2025 |
| Standards File | v9.1 | 2025-12-16 |

---

**Bookmark this page.** Use it every day.  
For details, refer to: `coding-standards-v9-1.md`
